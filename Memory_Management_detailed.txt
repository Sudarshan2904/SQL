***************************************************************************************************************************************************************************
Overhead Memory  = Memory allocated for VM related overhead.
Reserved Memory  = Memory allocated for Spark engine.
Storage Memory   = Memory for Cache and Persist operations
Execution Memory = Temporary memory required for Join, Shuffle, Sort, Aggregations, etc.
User Memory      = Memory for RDD related operations and user-defined data structures like Hash functions.

***************************************************************************************************************************************************************************
"Reserved Memory" by Spark Engine = 300 MB. (default configuration)

FOR EXECUTOR MEMORY ALLOCATION-
If X MB amount of heap-memory requested, then we're left with X-300 MB.
As soon as we request any amount of Executor Memory, we'll get Overhead mwemory which is off-heap memory (non-heap memory) needed for VM related overhead.
"Overhead Memory" = MAXIMUM of (10%X or 384MB)

Out of this,
Spark Unified Memory (Execution Memory + Storage Memory) = 60% of (X-300 MB) We'll consider it as SU.
                     "Execution Memory" = 50% of SU.
                     "Storage Memory"   = 50% of SU.
                    
"User Memory" = 40% of (X-300 MB)    

Hence, Requested X MB of executor memory =    300 MB          +   60% of (X-300 MB)     + 40% of (X-300 MB)
                                           "Reserved Memory"    "Spark Unified Memory"     "User Memory"
                +
       Overhead Memory                   =  MAXIMUM of (10%X or 384MB)
       
***************************************************************************************************************************************************************************
If X= 2048 MB
Then,
Reserved Memory      = 300 MB
Spark Unified Memory = 60% of (X-300 MB)  = 1048 MB
User Memory          = 40% of (X-300 MB)  =  700 MB
Overhead Memory      = MAXIMUM of (10%X or 384MB) = MAXIMUM of (204.8 MB or 384 MB) = 384 MB

Hence, for 2048 MB of executor memory requested, we need to think for = (2048 + 384) MB = 2432 MB Memory.

***************************************************************************************************************************************************************************
If we request 4192 MB (4GB) of off-heap memory on top of available allocated memory, this memory will get added to Spark Unified Memory always.
hence, if we consider above example of X= 2048 MB, we will now be having Spark Unified Memory = (1048 + 4192) MB = 5240 MB.
This is mostly done to avoid disk spill.

We can add this off-heap momory by-
config('spark.memory.offHeap.enabled', True)
config('spark.memory.offHeap.size', '4G')

***************************************************************************************************************************************************************************
If we want to statically allocate memory, first thing we need to do is to disable dynamic Allocation by-
config('spark.dynamicAllocation.enabled','false')

If we want to increase Spark Unified Memory to 80% which is default to 0.6 (i.e. 60%)-
config('spark.memory.fraction',0.8)

Out of total Spark Unified Memory(SU), if we want to increase Execution Memory to 80% which is default to 0.5 of SU (i.e. 50%)-
config('spark.memory.storageFraction',0.2)

***************************************************************************************************************************************************************************
If there is no Execution happening i.e. Execution Memory is free, then Storage can take Execution Memory and vice versa is also true.

Eviction process happens when there is no free memory available.
Execution can evict Storage Memory within the threshold limits.
However, Storage cannot evict Execution Memory.

Meaning of "Execution can evict Storage Memory within the threshold limits.":
If let's say, we've 1000 MB of Spark Unified Memory available.
500 MB is Execution Memory and 500 MB is Storage Memory.
Now consider we've cached data and it consumed 700 MB. (No Execution is happening currently, hence Execution Memory is free).
Now Execution starts, so we need Execution Memory but we are left with 300 MB for Execution. if we want total of 600 MB for Execution, then Spark can free up 200 MB Storage Memory for Execution  but can't free-up beyond 200 MB since 500 MB (counts to 50%) is threshold off Storage Memory. 

Meaning of "Storage cannot evict Execution Memory."
If let's say, we've 1000 MB of Spark Unified Memory available.
500 MB is Execution Memory and 500 MB is Storage Memory.
Now consider we invoked join operation (an Execution) which needs 700 MB. ((No Caching is happening currently, hence Storage Memory is free).
Now Caching starts, so we need Storage Memory but we are left with 300 MB. if we want total of 600 MB for Storage, Spark can't touch Execution Memory as Execution has priority.

***************************************************************************************************************************************************************************